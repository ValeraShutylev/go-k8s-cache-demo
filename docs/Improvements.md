## Improvements

Что стоит улучшить далее в сервисе go-cache-k8s-demo

1. Хранение ключей на удаление по TTL
2. Синхронизация данных в режиме работы Multi Pod
3. Реорганизация хранения данных на диске
4. Выделение функциональности удаления файлов с диска в отдельную Job / CronJob

---

### Хранение ключей на удаление по TTL

В данный момент. удаление объектов по истечению expiration date. происходит так:

1. Читаются все expiration date для объектов,
2. Сравниваются с текущим времением тикера
3. Если текущий тикер больше expiration date
4. Удаляются из мапы.

Данный подход рабочий, но не оптимальный. т.к. каждый N секунд/минут необходимо пройти все записи.

Улучшить можно несколькими способами.

#### 1. Buckets

Первый способ заключается в создании бакетов ключи которых являются timestamp, после которого данные должны быть удалены. Дискретизация бакетов может быть по 1 мин, 10 мин, час, и т.д. Т.о. в каждый из бакетов будут помещаться ключи согласно expiration date, перемещаться между бакетами при update.

**Плюсы:**

Точно известны ключи объектов на удаление. Удаление будет гранулярным.

**Минусы:**

В худшем случае нужно обходить полностью всю мапу (у всех данных совпадает expiration date)

Доп место в памяти для хранения ключей в бакете

#### 2. B-Tree

Аналог индексов в БД. Позволит также точно получить данные меньше текущего времени и найти ключи объектов к удалению.

**Плюсы:**

Точно известны ключи объектов на удаление. Удаление будет гранулярным.

**Минусы:**

Вставка нового ключа достаточно дорогостоящая

Довольно сложная реализация

---

### Синхронизация в режиме Multi Pod

В данный момент реализация подразумевает работу в режиме Single pod application. Такое не является полностью оптимальными `production-ready` решением.

Для обеспечения высокой доступности (HA), необходимо иметь N либо N-1 экземпляров приложения от количетсва топологических зон. (Например зон 3 (при 9 нодах), тогда оптимальное количество 2 либо 3 вразных зонах).

Соответственно, данные между экземплярами должны быть синхронизированны, т.к. запрос от внешней системы может обрабатываться на любом из экземпляров приложения.

Соответственно при вставке Object, необходимо передать копии данного Object с тем же ObjectId в другие экземпляры.

Для этого можно воспользоваться например Kafka и синхронизироваться через общий топик.

1. 1-й экземпляр получается запрос на добавление Object
2. Добавляет к себе в memory хранилище
3. Отправляет на диск (диск общий на PVC, S3 и т.д.)
4. отправляет в Kafka topic
5. 2-й и 3-й экземпляры получают копии и помещяют к себе в memory хранилище

Но при данном подходе появляется проблема необходимости согласования процессов синхронизации.

Данную проблему можно решить например используя `etcd` и паттерн 2cp, 3cp и т.д.


---

### Реорганизация хранения данных на диске

В данный момент данные на диске хранятся в единой директории, каждый object в своем файле по имени ключа.

Удалять по одному файлу также неоптимально, т.к. это отдельные запросы к OS, т.е становится занятым отдельный поток.

Стоит реорганизовать хранение на манер хранения в Memory Cache в отдельных директориях по времени жизни объектов и затем удалять сразу директорией по наступлению тика.


---

### Выделение функциональности удаления файлов с диска в отдельную Job / CronJob

Также дополнительно можно выделить функциональность по удалению с PVC файлов с Objects из приложения go cache в отдельное приложение запускаемое как Kubernetes Job / CronJob, что позволит оптимизировать работу приложения самого Cache и не делать запосы в диск из него (освободить потоки OS).

Синхронизацию работы джобы и Memory Cache можно сделать по времени (запускать по Cron Job в одно и то же время).

**Плюсы:**

Разделение обязанностей

Снижение ресурсов приложения Cache

Ресурсы необходимые для очистки необходимо выделять по расписанию

Минусы:

Ресурсов в сумме необходимо больше на работу Приложения + Job

Повышается вероятность того, что на диске. либо в памяти данные удалятся раньше.
